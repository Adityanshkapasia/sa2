{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "592dbb7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yd/cmkx7zcn0cl154l1q3lb92ww0000gn/T/ipykernel_41469/1031796009.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Train models and make predictions for each brand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbrand\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mtrain_and_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Plot the model predictions for each brand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/yd/cmkx7zcn0cl154l1q3lb92ww0000gn/T/ipykernel_41469/1031796009.py\u001b[0m in \u001b[0;36mtrain_and_predict\u001b[0;34m(brand)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Create a polynomial regression model (degree 2) for the current brand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPolynomialFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_train_brand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# Load the beer data\n",
    "beer_data = pd.read_csv('beer_foam.csv')\n",
    "\n",
    "# Consider the first 12 samples as the training set and the last 3 samples as the test set\n",
    "x_train = beer_data['Time'].to_numpy()[:12]\n",
    "x_test = beer_data['Time'].to_numpy()[12:]\n",
    "\n",
    "# Training and test labels\n",
    "t_train = beer_data.drop('Time', axis=1).iloc[:12]\n",
    "t_test = beer_data.drop('Time', axis=1).iloc[12:]\n",
    "\n",
    "# Initialize dictionaries to store models and predictions for each brand\n",
    "models = {}\n",
    "test_predictions = {}\n",
    "foam_height_predictions = {}\n",
    "\n",
    "# Define a function to train a model for each brand and make predictions\n",
    "def train_and_predict(brand):\n",
    "    # Extract the target values for the current brand\n",
    "    t_train_brand = t_train[brand].to_numpy()\n",
    "    \n",
    "    # Create a polynomial regression model (degree 2) for the current brand\n",
    "    model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "    model.fit(x_train.reshape(-1, 1), t_train_brand)\n",
    "    \n",
    "    # Store the trained model\n",
    "    models[brand] = model\n",
    "    \n",
    "    # Make predictions for the test data\n",
    "    test_predictions[brand] = model.predict(x_test.reshape(-1, 1))\n",
    "    \n",
    "    # Predict foam height at a specified time (e.g., 450 seconds)\n",
    "    time_to_predict = 450\n",
    "    foam_height_predictions[brand] = model.predict(np.array([[time_to_predict]]))[0]\n",
    "\n",
    "# Train models and make predictions for each brand\n",
    "for brand in t_train.columns:\n",
    "    train_and_predict(brand)\n",
    "\n",
    "# Plot the model predictions for each brand\n",
    "for brand in models.keys():\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(x_train, t_train[brand], label='Training Data')\n",
    "    plt.plot(x_test, test_predictions[brand], color='red', label='Model Prediction')\n",
    "    plt.title(f'Model Prediction for {brand} Beer')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Foam Height (cm)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Print the foam height predictions at 450 seconds for each brand\n",
    "for brand, prediction in foam_height_predictions.items():\n",
    "    print(f'Predicted foam height for {brand} at 450 seconds: {prediction:.2f} cm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0882a834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 25.515717586190323\n",
      "Mean Squared Error (MSE): 3007.8898321639376\n",
      "R-squared (R^2): 0.9440465034138786\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "hardware=pd.read_csv('machine.data',\n",
    "                 names=['Vendor','Model Name','MYCT','MMIN','MMAX','CACH','CHMIN','CHMAX','PRP','ERP'])\n",
    "\n",
    "\n",
    "# Select only the numerical features\n",
    "numerical_features = ['MYCT', 'MMIN', 'MMAX', 'CACH', 'CHMIN', 'CHMAX', 'PRP']\n",
    "data = hardware[numerical_features]\n",
    "\n",
    "# Target labels\n",
    "target = hardware['ERP']\n",
    "\n",
    "# Split the data into training (80%) and test (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate R-squared (R^2)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R-squared (R^2):\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a35d71c",
   "metadata": {},
   "source": [
    "- Data Collection & Preprocessing: Gather labeled email data and clean it by removing HTML tags and special characters. Tokenize text for analysis.\n",
    "- Feature Extraction: Select key features from email content, like word frequency and metadata. Encode these features numerically for machine learning.\n",
    "- Data Splitting: Divide the dataset into training (for model learning) and testing (for evaluation) sets. \n",
    "- Algorithm Selection: Choose a suitable machine learning algorithm for email classification, like Naive Bayes or SVM.\n",
    "- Model Training: Train the model using the training data to learn patterns distinguishing spam from ham.\n",
    "- Model Evaluation: Assess model performance on the testing dataset using metrics like accuracy and precision.\n",
    "- Hyperparameter Tuning: Fine-tune model settings to optimize its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f0e2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
